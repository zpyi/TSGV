slurm_config: big
task_type: local_predict
dataset:
  split: test # 没有split，就默认为train
  video_processor: VideoProcessor # 加载data/feat/feat_tacos_s3d/下的npy特征
  aligner: DSAligner # TacosAligner    # CrossTaskAligner   # 
  bert_name: bert-base-uncased
  meta_processor: TacosMetaProcessor
  test_path: data/tacos/split/train.json # 加载训练数据的标注，提取训练数据的特征用于下游任务
  # trainval_annotation: data/youcook/youcookii_annotations_trainval.json
  # use_annotation_text: true
  vfeat_dir: data/feat/feat_tacos_s3d
  text_processor: TextProcessor
  num_iso_layer: 12
  max_video_len: 1024 #32 
  max_len: 96 #1024+64  2048  # max_len - max_video_len 即为textseq长度（加了cls_token和sep_token）
  sliding_window: 32
  # sliding_window_size: 1024 # 统一最终的长度
fairseq:
  dataset:
    batch_size: 256
    valid_subset: test
    num_workers: 0
  common_eval:
    path: runs/retri/videoclip/checkpoint_best.pt
model:
  model_cls: MMFusionSeparate
  mm_encoder_cls: null
  video_encoder_cls: MMBertForEncoder
  text_encoder_cls: BertModel
  num_hidden_video_layers: 6
eval:
  save_path: runs/retri/videoclip/tacos_zs/eval
metric:  RetrievalMetric
predictor: RetrievalPredictor
